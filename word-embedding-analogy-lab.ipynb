{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Hmh8sFKyhsXG",
        "outputId": "6279cf4f-5cf5-4fbc-f51c-e0996299f4e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-01 11:28:59--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.tr.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 54.240.184.75, 54.240.184.45, 54.240.184.92, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|54.240.184.75|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1261500728 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.tr.300.vec.gz’\n",
            "\n",
            "cc.tr.300.vec.gz    100%[===================>]   1.17G   264MB/s    in 4.8s    \n",
            "\n",
            "2025-10-01 11:29:04 (253 MB/s) - ‘cc.tr.300.vec.gz’ saved [1261500728/1261500728]\n",
            "\n",
            "Requirement already satisfied: gensim==4.3.3 in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy==1.13.1 in /usr/local/lib/python3.12/dist-packages (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim==4.3.3) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim==4.3.3) (1.17.3)\n",
            "Model yükleniyor...\n",
            "Hazır!\n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.tr.300.vec.gz\n",
        "!gunzip cc.tr.300.vec.gz\n",
        "!pip install gensim==4.3.3 numpy==1.26.4 scipy==1.13.1\n",
        "from gensim.models import KeyedVectors\n",
        "print(\"Model yükleniyor...\")\n",
        "model=KeyedVectors.load_word2vec_format(\"cc.tr.300.vec\",\n",
        "limit=500000)\n",
        "print(\"Hazır!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Türkiye : Ankara :: İspanya : ?\n",
        "print(\"Türkiye : Ankara :: İspanya : ?\")\n",
        "print(model.most_similar(positive=[\"ankara\", \"ispanya\"], negative=[\"türkiye\"], topn=5))\n",
        "print()\n",
        "\n",
        "# Fransa : Paris :: İtalya : ?\n",
        "print(\"Fransa : Paris :: İtalya : ?\")\n",
        "print(model.most_similar(positive=[\"paris\", \"italya\"], negative=[\"fransa\"], topn=5))\n",
        "print()\n",
        "\n",
        "# Almanya : Berlin :: Japonya : ?\n",
        "print(\"Almanya : Berlin :: Japonya : ?\")\n",
        "print(model.most_similar(positive=[\"berlin\", \"japonya\"], negative=[\"almanya\"], topn=5))\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xI49ysnmit9F",
        "outputId": "083a3d73-4771-48e7-f83c-3077bed71541"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Türkiye : Ankara :: İspanya : ?\n",
            "[('italya', 0.5104808807373047), ('bursa', 0.5073603987693787), ('fransa', 0.5026073455810547), ('barcelona', 0.4961874485015869), ('Sevilla', 0.4955797791481018)]\n",
            "\n",
            "Fransa : Paris :: İtalya : ?\n",
            "[('venedik', 0.5814524292945862), ('milano', 0.570105254650116), ('pariste', 0.5643655061721802), ('Floransa', 0.5191888213157654), ('italyada', 0.5125287175178528)]\n",
            "\n",
            "Almanya : Berlin :: Japonya : ?\n",
            "[('tokyo', 0.559603214263916), ('singapur', 0.5243062973022461), ('japon', 0.5047327280044556), ('newyork', 0.4996938407421112), ('londra', 0.4907296597957611)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Soru 1 Ülke - Başkent\n",
        "\n",
        "| Analoji                         | Beklenen | Model Sonuçları (ilk 1–2)                                | Yorum                                                                                                                                |\n",
        "| ------------------------------- | -------- | -------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------ |\n",
        "| Türkiye : Ankara :: İspanya : ? | Madrid   | 1. İtalya (0.51), 2. Bursa (0.50), 3. Fransa (0.50)…     | Model Madrid’i bulamadı. Corpus’ta İspanya genelde başka ülkelerle birlikte anıldığı için başkent ilişkisini kaçırmış.               |\n",
        "| Fransa : Paris :: İtalya : ?    | Roma     | 1. Venedik (0.58), 2. Milano (0.57), 3. Paris’te (0.56)… | Roma yerine ünlü İtalya şehirlerini (Venedik, Milano, Floransa) getirdi. Yani ülke–başkent yerine “ülke–şehrin” ilişkisini öğrenmiş. |\n",
        "| Almanya : Berlin :: Japonya : ? | Tokyo    | 1. Tokyo (0.55), 2. Singapur (0.52)…                     | Burada doğru sonucu (Tokyo) buldu . Model Japonya–Tokyo eşleşmesini öğrenmiş.                                                       |\n"
      ],
      "metadata": {
        "id": "gspYNPNKjOm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kral : Kraliçe :: Erkek : ?\n",
        "print(\"Kral : Kraliçe :: Erkek : ?\")\n",
        "print(model.most_similar(positive=[\"kraliçe\",\"erkek\"], negative=[\"kral\"], topn=5))\n",
        "print()\n",
        "\n",
        "# Gündüz : Gece :: Yaz : ?\n",
        "print(\"Gündüz : Gece :: Yaz : ?\")\n",
        "print(model.most_similar(positive=[\"gece\",\"yaz\"], negative=[\"gündüz\"], topn=5))\n",
        "print()\n",
        "\n",
        "# Öğretmen : Okul :: Doktor : ?\n",
        "print(\"Öğretmen : Okul :: Doktor : ?\")\n",
        "print(model.most_similar(positive=[\"okul\",\"doktor\"], negative=[\"öğretmen\"], topn=5))\n",
        "print()\n",
        "\n",
        "\n",
        "# Kendi analogimiz: Ay : Gece :: Güneş : ?\n",
        "print(\"Ay : Gece :: Güneş : ?\")\n",
        "result_custom = model.most_similar(positive=[\"gece\",\"güneş\"], negative=[\"ay\"], topn=5)\n",
        "print(result_custom)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "holBFke5jDS1",
        "outputId": "4a681291-65b6-481e-8df0-4b877fb69d71"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kral : Kraliçe :: Erkek : ?\n",
            "[('kadın', 0.6786535978317261), ('kız', 0.6334383487701416), ('kadın-', 0.5685897469520569), ('erkek-kadın', 0.5654035806655884), ('bayan', 0.5578188300132751)]\n",
            "\n",
            "Gündüz : Gece :: Yaz : ?\n",
            "[('Yaz', 0.6220954060554504), ('kış', 0.6100205183029175), ('sonbahar', 0.5917434692382812), ('bahar', 0.5499704480171204), ('ilkbahar', 0.5494310259819031)]\n",
            "\n",
            "Öğretmen : Okul :: Doktor : ?\n",
            "[('hastane', 0.728849470615387), ('hastahane', 0.6638420224189758), ('hastanenin', 0.5605310201644897), ('hastaneler', 0.540983259677887), ('hastahaneler', 0.5363527536392212)]\n",
            "\n",
            "Ay : Gece :: Güneş : ?\n",
            "[('gündüz', 0.6085719466209412), ('güneşin', 0.5537223219871521), ('Gece', 0.5426763296127319), ('güneşiyle', 0.5351989269256592), ('güneşinin', 0.5309818387031555)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Soru 2 – Kavramsal İlişkiler\n",
        "\n",
        "**Kral : Kraliçe :: Erkek : ?**\n",
        "\n",
        "Model doğru şekilde “kadın” sonucunu ilk sırada bulmuş.\n",
        "\n",
        "Bu, modelin cinsiyet karşılıklarını ve toplumsal cinsiyet ilişkilerini iyi öğrendiğini gösteriyor.\n",
        "\n",
        "Ayrıca “kız”, “bayan” gibi varyasyonların da çıkması, modelin eşanlamlıları da yakalayabildiğini gösteriyor.\n",
        "\n",
        "**Gündüz : Gece :: Yaz : ?**\n",
        "\n",
        "Model mevsim ve zaman ilişkilerini kavrayabiliyor.\n",
        "\n",
        "İlk sırada “yaz” çıkmış olsa da, ikinci sırada doğru cevap “kış” mevcut.\n",
        "\n",
        "Bu durum, modelin bazı bağlamlarda frekansa bağlı olarak farklı sonuçlar üretebileceğini gösteriyor.\n",
        "\n",
        "**Öğretmen : Okul :: Doktor : ?**\n",
        "\n",
        "Model bağlamsal ilişkileri çok başarılı şekilde yakalamış; “hastane” ve türevleri en üst sıralarda.\n",
        "\n",
        "Bu, meslek ve mekan ilişkilerini öğrenebildiğini gösteriyor.\n",
        "\n",
        "Farklı kelime varyasyonlarının çıkması, modelin geniş bir kelime kullanım bilgisini kapsadığını gösteriyor.\n",
        "\n",
        "**Ay : Gece :: Güneş : ?**\n",
        "\n",
        "Model doğru şekilde “gündüz” sonucunu ilk sırada bulmuş\n",
        "\n",
        "Bu, modelin doğa olayları ve zaman kavramları arasındaki ilişkiyi kavrayabildiğini gösteriyor.\n",
        "\n",
        "Ayrıca “güneşin”, “güneşiyle” gibi varyasyonların da çıkması, modelin kelime türevlerini ve bağlam ilişkilerini yakalayabildiğini gösteriyor.\n"
      ],
      "metadata": {
        "id": "cmWDoboKjfb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hemşire : Kadın :: Doktor : ?\n",
        "print(\"Hemşire : Kadın :: Doktor : ?\")\n",
        "print(model.most_similar(positive=[\"kadın\",\"doktor\"], negative=[\"hemşire\"], topn=5))\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rqiwXD6WjZz6",
        "outputId": "47dd65cf-da36-44da-8404-784cddc25943"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hemşire : Kadın :: Doktor : ?\n",
            "[('kadının', 0.6143438816070557), ('erkek', 0.6107356548309326), ('kadınlar', 0.5653315782546997), ('jinekolog', 0.5632423758506775), ('kadını', 0.5555832982063293)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Soru 3 –  Bias Gözlem\n",
        "\n",
        "Model, hemşire–kadın ve doktor–erkek eşleşmelerini veri üzerinden öğrenmiş görünüyor.\n",
        "\n",
        "Çıkan ilk sonuçların “kadının” ve “kadınlar” olması, modelin toplumsal cinsiyet önyargısını yansıttığını gösteriyor.\n",
        "\n",
        "Bu, word embedding modellerinin eğitim verisindeki önyargıları aynen öğrenip sonuçlara taşıyabileceğini ortaya koyuyor."
      ],
      "metadata": {
        "id": "4CRccq_TkFZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1️⃣ Elma : Meyve :: Havuç : ?\n",
        "print(\"Elma : Meyve :: Havuç : ?\")\n",
        "result1 = model.most_similar(positive=[\"meyve\",\"havuç\"], negative=[\"elma\"], topn=5)\n",
        "print(result1)\n",
        "print()\n",
        "\n",
        "# 2️⃣ Kitap : Kütüphane :: Para : ?\n",
        "print(\"Kitap : Kütüphane :: Para : ?\")\n",
        "result2 = model.most_similar(positive=[\"kütüphane\",\"para\"], negative=[\"kitap\"], topn=5)\n",
        "print(result2)\n",
        "print()\n",
        "\n",
        "# 3️⃣ Beşiktaş : İstanbul :: Barcelona : ?\n",
        "print(\"Beşiktaş : İstanbul :: Barcelona : ?\")\n",
        "result3 = model.most_similar(positive=[\"istanbul\",\"barcelona\"], negative=[\"beşiktaş\"], topn=5)\n",
        "print(result3)\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "L5OSk2TWjsyo",
        "outputId": "08401b65-519f-4397-e12a-380819541277"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elma : Meyve :: Havuç : ?\n",
            "[('sebze', 0.7243412137031555), ('sebzeler', 0.6214406490325928), ('sebzelere', 0.6159278750419617), ('meyve-sebze', 0.5970016121864319), ('sebze-meyve', 0.5965595841407776)]\n",
            "\n",
            "Kitap : Kütüphane :: Para : ?\n",
            "[('paralar', 0.48872601985931396), ('parayı', 0.47033238410949707), ('paraları', 0.46755722165107727), ('birimi', 0.46665671467781067), ('döviz', 0.4539383351802826)]\n",
            "\n",
            "Beşiktaş : İstanbul :: Barcelona : ?\n",
            "[('ankara', 0.536542534828186), ('londra', 0.5338242053985596), ('ispanya', 0.47953665256500244), ('tokyo', 0.47438669204711914), ('italya', 0.4721299111843109)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Soru 4 – Kompleks İlişkiler\n",
        "\n",
        "#### 1️ Elma : Meyve :: Havuç : ?\n",
        "**Model Sonuçları:** Sebze (0.724), Sebzeler (0.621), Sebzelere (0.616), Meyve-sebze (0.597), Sebze-meyve (0.597)  \n",
        "**Yorum:**  Model doğru sonucu bulmuş: Havuç → Sebze. Türevler de çıkmış, kategori ilişkileri iyi öğrenilmiş.\n",
        "\n",
        "#### 2️ Kitap : Kütüphane :: Para : ?\n",
        "**Model Sonuçları:** Paralar (0.489), Parayı (0.470), Paraları (0.468), Birimi (0.467), Döviz (0.454)  \n",
        "**Yorum:**  Beklenen “Banka” yerine ekonomik bağlam kelimeleri çıkmış. Model bağlamı tam anlayamamış.\n",
        "\n",
        "#### 3️ Beşiktaş : İstanbul :: Barcelona : ?\n",
        "**Model Sonuçları:** Ankara (0.537), Londra (0.534), İspanya (0.480), Tokyo (0.474), İtalya (0.472)  \n",
        "**Yorum:**  Beklenen “İspanya” üçüncü sırada çıkmış. Model, Barcelona’yı daha çok futbol veya şehir bağlamında öğrenmiş.\n",
        "\n",
        "#####  Genel Tartışma\n",
        "- Model bazı ilişkileri doğru, bazılarını bağlam farkı nedeniyle yanlış veya gecikmeli çıkarmış.  \n",
        "- Doğru çıkmayan örnekler genellikle:  \n",
        "  - Kelimenin corpus’ta az veya farklı bağlamlarda geçmesi  \n",
        "  - Çok anlamlı kelimelerin birden fazla bağlamda öğrenilmesi  \n",
        "  - Modelin istatistiksel co-occurrence bazlı çalışması\n"
      ],
      "metadata": {
        "id": "6V6-ddC4l6rA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kalem : Yazmak :: Fırça : ?\n",
        "result_custom2 = model.most_similar(positive=[\"yazmak\",\"fırça\"], negative=[\"kalem\"], topn=5)\n",
        "print(result_custom2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "10lF5DrhlemS",
        "outputId": "cf7d3f18-ef00-416c-a6f3-b9f88c82d15d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('yayınlamak', 0.526287853717804), ('yazmamak', 0.5225868821144104), ('yorumlamak', 0.5053537487983704), ('okumak', 0.4803018867969513), ('Yazmak', 0.4748064875602722)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Soru 5 – Yaratıcı Analogi\n",
        "\n",
        "#### Kalem : Yazmak :: Fırça : ?\n",
        "**Model Sonuçları:** Yayınlamak (0.526), Yazmamak (0.523), Yorumlamak (0.505), Okumak (0.480), Yazmak (0.475)  \n",
        "**Beklenen Cevap:** Boyamak  \n",
        "**Tartışma ve Yorum:**  \n",
        "Model beklenen “boyamak” sonucunu verememiş. Bunun sebebi, embedding modelinin “fırça” kelimesini corpus’ta çoğunlukla yazı, sanat veya sanat yorumlama bağlamında görmesi olabilir.  \n",
        "Çıkan sonuçlar (“yayınlamak”, “yorumlamak”, “okumak”) daha çok metin ve yayıncılık bağlamıyla ilişkili. Bu, modelin kelimenin kullanım bağlamına bağlı olduğunu gösteriyor.  \n",
        "“Yazmak” ve “yazmamak” gibi kelimeler, modelin temel eşleştirme mantığını kavradığını ama araç–işlev ilişkisini yeterince öğrenemediğini gösteriyor.  \n",
        "Bu durum, embedding modellerinin somut araç–işlev ilişkilerinde sınırlı kalabileceğini ve sonuçların her zaman mantıklı çıkmayabileceğini ortaya koyuyor.\n"
      ],
      "metadata": {
        "id": "UI6FecY4mi54"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eJsB1UDqmYYb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}